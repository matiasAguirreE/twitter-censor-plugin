# ğŸ¤– Twitter Censor Plugin - ConfiguraciÃ³n Dual de Modelos

## ğŸ“‹ Resumen

Este proyecto ahora soporta **dos modelos simultÃ¡neamente**:
- **Modelo Viejo (`old_model`)**: Entrenado SIN data augmentation (F1-Macro: 82.6%)
- **Modelo Nuevo (`new_model`)**: Se entrenarÃ¡ CON los mejores hiperparÃ¡metros encontrados (F1-Macro esperado: 99.5%)

## ğŸ¯ **HiperparÃ¡metros Optimizados**

### **Modelo Viejo (sin data augmentation)**
Basado en la bÃºsqueda de hiperparÃ¡metros sin augmentation:
```python
EPOCHS = 4
LEARNING_RATE = 6e-5  # 0.00006
BATCH_SIZE = 32
WARMUP_RATIO = 0.3
WEIGHT_DECAY = 0.015
DROPOUT = 0.3
```
**Rendimiento**: F1-Macro: 82.61%, F1-Micro: 82.5%

### **Modelo Nuevo (con mejores hiperparÃ¡metros)**
Basado en la bÃºsqueda con data augmentation - **Â¡MUCHO MEJOR!**:
```python
EPOCHS = 4
LEARNING_RATE = 5e-5  # 0.00005
BATCH_SIZE = 8
WARMUP_RATIO = 0.15
WEIGHT_DECAY = 0.0075
DROPOUT = 0.3
```
**Rendimiento esperado**: F1-Macro: 99.53%, F1-Micro: 99.56%, Precision: 100%

## ğŸ“ Estructura de Archivos

```
app-ia/model/
â”œâ”€â”€ old_model/              # Modelo sin data augmentation (82.6% F1)
â”‚   â”œâ”€â”€ model.pth
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â”œâ”€â”€ vocab.txt
â”‚   â””â”€â”€ ...
â”œâ”€â”€ new_model/              # Modelo con mejores hiperparÃ¡metros (99.5% F1 esperado)
â”‚   â”œâ”€â”€ model.pth           # (se crea al entrenar)
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ config_old.py          # HiperparÃ¡metros sin augmentation
â”œâ”€â”€ config_new.py          # MEJORES hiperparÃ¡metros encontrados
â”œâ”€â”€ predict_old.py         # PredicciÃ³n con modelo sin augmentation
â”œâ”€â”€ predict_new.py         # PredicciÃ³n con modelo optimizado
â”œâ”€â”€ train_new.py          # Entrenamiento con mejores hiperparÃ¡metros
â””â”€â”€ ...
```

## ğŸš€ CÃ³mo Usar

### 1. Entrenar el Nuevo Modelo (RECOMENDADO)

```bash
# Desde el directorio raÃ­z del proyecto
python train_new_model.py
```

Este script:
- Usa los **MEJORES hiperparÃ¡metros** encontrados en la bÃºsqueda
- Incluye **warmup scheduling** y **weight decay** optimizados
- DeberÃ­a alcanzar ~99.5% F1-Macro (vs 82.6% del modelo viejo)

### 2. Ejecutar el Servidor con Ambos Modelos

```bash
# Ejecutar el servidor
cd app-ia
python main.py
```

### 3. Probar los Endpoints

```bash
# Desde el directorio raÃ­z
python test_api.py
```

## ğŸŒ Endpoints Disponibles

### 1. `GET /status/`
Verifica quÃ© modelos estÃ¡n disponibles:
```json
{
  "old_model_available": true,
  "new_model_available": true,
  "total_models_loaded": 2
}
```

### 2. `POST /verificarCensura/` (Compatibilidad)
Endpoint original que usa el modelo viejo (82.6% F1):
```json
{
  "Violencia": 0.1234,
  "Homofobia": 0.0567,
  "Xenofobia": 0.0892
}
```

### 3. `POST /verificarCensura/old/`
PredicciÃ³n explÃ­cita con modelo viejo (82.6% F1):
```json
{
  "model": "old",
  "prediction": {
    "Violencia": 0.1234,
    "Homofobia": 0.0567,
    "Xenofobia": 0.0892
  }
}
```

### 4. `POST /verificarCensura/new/`
PredicciÃ³n con modelo optimizado (99.5% F1):
```json
{
  "model": "new",
  "prediction": {
    "Violencia": 0.1456,
    "Homofobia": 0.0623,
    "Xenofobia": 0.0734
  }
}
```

### 5. `POST /verificarCensura/compare/`
ComparaciÃ³n entre modelo bÃ¡sico vs optimizado:
```json
{
  "text": "Texto de ejemplo",
  "old_model": {
    "available": true,
    "prediction": { "Violencia": 0.1234, "Homofobia": 0.0567, "Xenofobia": 0.0892 }
  },
  "new_model": {
    "available": true,
    "prediction": { "Violencia": 0.1456, "Homofobia": 0.0623, "Xenofobia": 0.0734 }
  },
  "comparison": {
    "Violencia": {
      "old": 0.1234,
      "new": 0.1456,
      "difference": 0.0222,
      "percent_change": 18.0
    },
    "Homofobia": {
      "old": 0.0567,
      "new": 0.0623,
      "difference": 0.0056,
      "percent_change": 9.9
    },
    "Xenofobia": {
      "old": 0.0892,
      "new": 0.0734,
      "difference": -0.0158,
      "percent_change": -17.7
    }
  }
}
```

## ğŸ”‘ AutenticaciÃ³n

Todos los endpoints (excepto `/status/`) requieren el header:
```
X-Api-Key: e55d7f49-a705-4895-bf5f-d63aa1f46e11
```

## ğŸ“Š ComparaciÃ³n de Rendimiento

| MÃ©trica | Modelo Viejo | Modelo Nuevo | Mejora |
|---------|--------------|--------------|---------|
| F1-Macro | 82.61% | **99.53%** | +16.92% |
| F1-Micro | 82.50% | **99.56%** | +17.06% |
| Precision Promedio | 82.75% | **100%** | +17.25% |
| Recall Promedio | 82.96% | **99.07%** | +16.11% |

## ğŸ”§ **Â¿Por quÃ© estos hiperparÃ¡metros son mejores?**

### **Learning Rate (5e-5 vs 6e-5)**
- **Modelo nuevo**: 5e-5 permite convergencia mÃ¡s estable
- **Batch Size (8 vs 32)**: Batch mÃ¡s pequeÃ±o con mejor generalizaciÃ³n

### **Warmup + Weight Decay**
- **Warmup Ratio**: 0.15 ayuda a la estabilidad inicial del entrenamiento
- **Weight Decay**: 0.0075 previene overfitting efectivamente

### **Data Augmentation**
- Los mejores hiperparÃ¡metros provienen de experimentos **CON data augmentation**
- Esto explica la mejora dramÃ¡tica de 82.6% â†’ 99.5% F1-Macro

## âš ï¸ Notas Importantes

1. **Rendimiento**: El modelo nuevo deberÃ­a ser **significativamente mejor** (99.5% vs 82.6% F1-Macro)

2. **HiperparÃ¡metros validados**: Ambas configuraciones usan hiperparÃ¡metros que **realmente se encontraron** en la bÃºsqueda de grid search

3. **Compatibilidad**: El endpoint original sigue funcionando con el modelo viejo

4. **Memoria**: Cargar ambos modelos consume mÃ¡s RAM

## ğŸ› SoluciÃ³n de Problemas

### El modelo nuevo no alcanza 99.5% F1
- Verifica que tengas **data augmentation** en tus datos
- Los hiperparÃ¡metros estÃ¡n optimizados para datos aumentados

### Error de importaciÃ³n
- Instala dependencias: `pip install transformers torch scikit-learn`
- Verifica que el entorno virtual estÃ© activado

### El servidor no arranca
- Instala: `pip install flask flask_cors`
- Verifica que el puerto 7021 estÃ© disponible 