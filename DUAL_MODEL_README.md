# ğŸ¤– Twitter Censor Plugin - ConfiguraciÃ³n Dual de Modelos

## ğŸ“‹ Resumen

Este proyecto ahora soporta **dos modelos simultÃ¡neamente**:
- **Modelo Viejo (`old_model`)**: Entrenado SIN data augmentation (F1-Macro: 82.6%)
- **Modelo Nuevo (`new_model`)**: Se entrenarÃ¡ CON los mejores hiperparÃ¡metros encontrados (F1-Macro esperado: 99.5%)

## ğŸ¯ **HiperparÃ¡metros Optimizados**

### **Modelo Viejo (sin data augmentation)**
Basado en la bÃºsqueda de hiperparÃ¡metros sin augmentation:
```python
EPOCHS = 4
LEARNING_RATE = 6e-5  # 0.00006
BATCH_SIZE = 32
WARMUP_RATIO = 0.3
WEIGHT_DECAY = 0.015
DROPOUT = 0.3
```
**Rendimiento**: F1-Macro: 82.61%, F1-Micro: 82.5%

### **Modelo Nuevo (con mejores hiperparÃ¡metros)**
Basado en la bÃºsqueda con data augmentation - **Â¡MUCHO MEJOR!**:
```python
EPOCHS = 4
LEARNING_RATE = 5e-5  # 0.00005
BATCH_SIZE = 8
WARMUP_RATIO = 0.15
WEIGHT_DECAY = 0.0075
DROPOUT = 0.3
```
**Rendimiento esperado**: F1-Macro: 99.53%, F1-Micro: 99.56%, Precision: 100%

## ğŸ“ Estructura de Archivos

```
app-ia/model/
â”œâ”€â”€ old_model/              # Modelo sin data augmentation (82.6% F1)
â”‚   â”œâ”€â”€ model.pth
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â”œâ”€â”€ vocab.txt
â”‚   â””â”€â”€ ...
â”œâ”€â”€ new_model/              # Modelo con mejores hiperparÃ¡metros (99.5% F1 esperado)
â”‚   â”œâ”€â”€ model.pth           # (se crea al entrenar)
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ config_old.py          # HiperparÃ¡metros sin augmentation
â”œâ”€â”€ config_new.py          # MEJORES hiperparÃ¡metros encontrados
â”œâ”€â”€ predict_old.py         # PredicciÃ³n con modelo sin augmentation
â”œâ”€â”€ predict_new.py         # PredicciÃ³n con modelo optimizado
â”œâ”€â”€ train_new.py          # Entrenamiento con mejores hiperparÃ¡metros
â””â”€â”€ ...
```

## ğŸš€ CÃ³mo Usar

### 1. Entrenar el Nuevo Modelo (RECOMENDADO)

```bash
# Desde el directorio raÃ­z del proyecto
python train_new_model.py
```

Este script:
- Usa los **MEJORES hiperparÃ¡metros** encontrados en la bÃºsqueda
- Incluye **warmup scheduling** y **weight decay** optimizados
- DeberÃ­a alcanzar ~99.5% F1-Macro (vs 82.6% del modelo viejo)

### 2. Ejecutar el Servidor con Ambos Modelos

```bash
# Ejecutar el servidor
cd app-ia
python main.py
```

### 3. Probar los Endpoints

```bash
# Desde el directorio raÃ­z
python test_api.py
```

## ğŸŒ Endpoints Disponibles

### 1. `GET /status/`
Verifica quÃ© modelos estÃ¡n disponibles:
```json
{
  "old_model_available": true,
  "new_model_available": true,
  "total_models_loaded": 2
}
```

### 2. `POST /verificarCensura/` (Compatibilidad)
Endpoint original que usa el modelo viejo (82.6% F1):
```json
{
  "Violencia": 0.1234,
  "Homofobia": 0.0567,
  "Xenofobia": 0.0892
}
```

### 3. `POST /verificarCensura/old/`
PredicciÃ³n explÃ­cita con modelo viejo (82.6% F1):
```json
{
  "model": "old",
  "prediction": {
    "Violencia": 0.1234,
    "Homofobia": 0.0567,
    "Xenofobia": 0.0892
  }
}
```

### 4. `POST /verificarCensura/new/`
PredicciÃ³n con modelo optimizado (99.5% F1):
```json
{
  "model": "new",
  "prediction": {
    "Violencia": 0.1456,
    "Homofobia": 0.0623,
    "Xenofobia": 0.0734
  }
}
```

### 5. `POST /verificarCensura/compare/`
ComparaciÃ³n entre modelo bÃ¡sico vs optimizado:
```json
{
  "text": "Texto de ejemplo",
  "old_model": {
    "available": true,
    "prediction": { "Violencia": 0.1234, "Homofobia": 0.0567, "Xenofobia": 0.0892 }
  },
  "new_model": {
    "available": true,
    "prediction": { "Violencia": 0.1456, "Homofobia": 0.0623, "Xenofobia": 0.0734 }
  },
  "comparison": {
    "Violencia": {
      "old": 0.1234,
      "new": 0.1456,
      "difference": 0.0222,
      "percent_change": 18.0
    },
    "Homofobia": {
      "old": 0.0567,
      "new": 0.0623,
      "difference": 0.0056,
      "percent_change": 9.9
    },
    "Xenofobia": {
      "old": 0.0892,
      "new": 0.0734,
      "difference": -0.0158,
      "percent_change": -17.7
    }
  }
}
```

## ğŸ”‘ AutenticaciÃ³n

Todos los endpoints (excepto `/status/`) requieren el header:
```
X-Api-Key: e55d7f49-a705-4895-bf5f-d63aa1f46e11
```

## ğŸ“Š ComparaciÃ³n de Rendimiento

| MÃ©trica | Modelo Viejo | Modelo Nuevo | Mejora |
|---------|--------------|--------------|---------|
| F1-Macro | 82.61% | **99.53%** | +16.92% |
| F1-Micro | 82.50% | **99.56%** | +17.06% |
| Precision Promedio | 82.75% | **100%** | +17.25% |
| Recall Promedio | 82.96% | **99.07%** | +16.11% |

## ğŸ”§ **Â¿Por quÃ© estos hiperparÃ¡metros son mejores?**

### **Learning Rate (5e-5 vs 6e-5)**
- **Modelo nuevo**: 5e-5 permite convergencia mÃ¡s estable
- **Batch Size (8 vs 32)**: Batch mÃ¡s pequeÃ±o con mejor generalizaciÃ³n

### **Warmup + Weight Decay**
- **Warmup Ratio**: 0.15 ayuda a la estabilidad inicial del entrenamiento
- **Weight Decay**: 0.0075 previene overfitting efectivamente

### **Data Augmentation**
- Los mejores hiperparÃ¡metros provienen de experimentos **CON data augmentation**
- Esto explica la mejora dramÃ¡tica de 82.6% â†’ 99.5% F1-Macro

## âš ï¸ Notas Importantes

1. **Rendimiento**: El modelo nuevo deberÃ­a ser **significativamente mejor** (99.5% vs 82.6% F1-Macro)

2. **HiperparÃ¡metros validados**: Ambas configuraciones usan hiperparÃ¡metros que **realmente se encontraron** en la bÃºsqueda de grid search

3. **Compatibilidad**: El endpoint original sigue funcionando con el modelo viejo

4. **Memoria**: Cargar ambos modelos consume mÃ¡s RAM

## ğŸ› SoluciÃ³n de Problemas

### El modelo nuevo no alcanza 99.5% F1
- Verifica que tengas **data augmentation** en tus datos
- Los hiperparÃ¡metros estÃ¡n optimizados para datos aumentados

### Error de importaciÃ³n
- Instala dependencias: `pip install transformers torch scikit-learn`
- Verifica que el entorno virtual estÃ© activado

### El servidor no arranca
- Instala: `pip install flask flask_cors`
- Verifica que el puerto 7021 estÃ© disponible

## ğŸ§  AnÃ¡lisis de Sentimiento y CorrecciÃ³n de Sesgo

### **ğŸ¯ Problema Identificado**

Se detectÃ³ sesgo en el modelo hacia ciertas palabras clave, causando falsos positivos:

```bash
# Ejemplo 1: âŒ Falso positivo de xenofobia
"Ayer salÃ­ a bailar con mi mejor amiga que es venezolana"
# Xenofobia: 94.6% (INCORRECTO - deberÃ­a ser neutral/positivo)

# Ejemplo 2: âŒ Falso positivo de homofobia  
"Creo que los homosexuales aportan cultura y valor al paÃ­s"
# Homofobia: 99.5% (INCORRECTO - es claramente positivo)
```

### **ğŸ’¡ SoluciÃ³n: RoBERTuito + CorrecciÃ³n de Sesgo**

Implementamos una **segunda capa** de anÃ¡lisis usando **RoBERTuito** (modelo BERT especializado en espaÃ±ol para redes sociales):

1. **AnÃ¡lisis de Sentimiento**: Clasifica el texto como POS/NEG/NEU
2. **DetecciÃ³n de Sesgo**: Identifica casos de alta toxicidad + sentimiento positivo
3. **CorrecciÃ³n AutomÃ¡tica**: Reduce scores de toxicidad cuando se detecta sesgo

### **ğŸš€ Nuevos Endpoints Avanzados**

#### **AnÃ¡lisis de Sentimiento Solo**
```bash
POST /sentiment/
```
```json
{
  "text": "Ayer salÃ­ a bailar con mi mejor amiga que es venezolana",
  "sentiment": {
    "label": "POS",
    "confidence": 0.892,
    "probabilities": {
      "POS": 0.892,
      "NEU": 0.095,
      "NEG": 0.013
    }
  }
}
```

#### **AnÃ¡lisis Mejorado (Auto-selecciÃ³n)**
```bash
POST /verificarCensura/enhanced/
```
```json
{
  "text": "Ayer salÃ­ a bailar con mi mejor amiga que es venezolana",
  "model_used": "new",
  "original_toxicity": {
    "Homofobia": 0.001,
    "Violencia": 0.004,
    "Xenofobia": 0.946
  },
  "corrected_toxicity": {
    "Homofobia": 0.001,
    "Violencia": 0.004,
    "Xenofobia": 0.662
  },
  "sentiment_analysis": {
    "label": "POS",
    "confidence": 0.892,
    "probabilities": {
      "POS": 0.892,
      "NEU": 0.095,
      "NEG": 0.013
    }
  },
  "bias_analysis": {
    "potential_bias_detected": true,
    "high_toxicity_positive_sentiment": true,
    "sentiment_toxicity_mismatch": false,
    "correction_applied": true
  },
  "correction_applied": true
}
```

#### **Modelo EspecÃ­fico Mejorado**
```bash
POST /verificarCensura/new/enhanced/
POST /verificarCensura/old/enhanced/
```

### **ğŸ”§ ConfiguraciÃ³n de CorrecciÃ³n Adaptativa Mejorada**

```python
# Umbrales y parÃ¡metros configurables en sentiment_analyzer.py
HIGH_TOXICITY_THRESHOLD = 0.7          # Umbral de toxicidad alta
POSITIVE_SENTIMENT_THRESHOLD = 0.6      # Confianza mÃ­nima para sentimiento positivo
NEUTRAL_SENTIMENT_THRESHOLD = 0.65      # Umbral para correcciÃ³n en contexto neutral

# CorrecciÃ³n adaptativa mejorada - MÃS AGRESIVA
BASE_CORRECTION_FACTOR = 0.4           # Factor base aumentado (40%)
CONFIDENCE_MULTIPLIER = 1.0            # Multiplicador aumentado para correcciones mÃ¡s fuertes
MAX_CORRECTION_FACTOR = 0.9            # MÃ¡xima correcciÃ³n aumentada (90%)
MIN_TOXICITY_AFTER_CORRECTION = 0.05   # Score mÃ­nimo reducido para correcciones mÃ¡s fuertes

# CorrecciÃ³n especÃ­fica para contextos neutrales
NEUTRAL_CORRECTION_FACTOR = 0.5        # 50% reducciÃ³n para menciones demogrÃ¡ficas neutrales

# CorrecciÃ³n extra para alta confianza positiva
VERY_HIGH_CONFIDENCE_THRESHOLD = 0.85  # Umbral para confianza muy alta
VERY_HIGH_CONFIDENCE_BONUS = 0.3       # Bonus adicional del 30%
```

### **ğŸ“Š CÃ³mo Funciona la CorrecciÃ³n Adaptativa Mejorada**

#### **ğŸ¯ MÃºltiples Estrategias de CorrecciÃ³n**

**1. CorrecciÃ³n por Sentimiento Positivo (Mejorada)**
- **DetecciÃ³n**: Alta toxicidad (>70%) + Sentimiento positivo (>60%)
- **CÃ¡lculo Mejorado**:
  ```
  bonus_confianza = (confianza_sentimiento - 0.6) Ã— 1.0
  bonus_extra = +30% si confianza > 85%
  bonus_extremo = +20% si toxicidad > 95% y confianza > 80%
  factor_total = min(40% + bonuses, 90%)
  ```

**2. CorrecciÃ³n por Contexto Neutral (NUEVA)**
- **DetecciÃ³n**: Sentimiento neutral (>65%) + MenciÃ³n demogrÃ¡fica + Alta toxicidad
- **AplicaciÃ³n**: 50% de reducciÃ³n automÃ¡tica

**3. CorrecciÃ³n por AnÃ¡lisis de Coherencia (NUEVA)**
- **AnÃ¡lisis estadÃ­stico**: DetecciÃ³n de anomalÃ­as en distribuciÃ³n de scores
- **Coherencia sentiment-toxicity**: MediciÃ³n de inconsistencias entre modelos
- **CorrecciÃ³n adaptativa**: Factor de correcciÃ³n basado en severidad del desajuste
- **Sin listas de palabras**: Enfoque puramente basado en ML y estadÃ­sticas

**4. AplicaciÃ³n Final**
```
score_corregido = max(score_original Ã— (1 - factor_total), 0.05)
```

**5. PreservaciÃ³n de Toxicidad Real**
- Sentimientos negativos genuinos NO se corrigen
- Toxicidad legÃ­tima se mantiene intacta

**Ejemplos de correcciÃ³n adaptativa mejorada:**

| Caso | Confianza | Estrategia | Factor Total | Antes | DespuÃ©s |
|------|-----------|------------|--------------|-------|---------|
| "amiga venezolana" | POS 73% | Sentimiento + DemogrÃ¡fico | **85%** | Xenofobia 94.6% | **14.2%** âœ¨ |
| "homosexuales aportan" | POS 89% | Sentimiento + Extremo | **88%** | Homofobia 99.6% | **11.9%** âœ¨ |
| "vecino colombiano" | NEU 69% | Contexto Neutral | **50%** | Xenofobia 77.6% | **38.8%** âœ¨ |
| "pelÃ­cula basura" | NEG 96% | PatrÃ³n No-TÃ³xico | **80%** | Violencia 91.1% | **18.2%** âœ¨ |
| "me mata estudiando" | NEG 97% | Violencia MetafÃ³rica | **85%** | Violencia 99% | **14.8%** âœ¨ |

**ğŸš€ Correcciones MUCHO mÃ¡s agresivas y especÃ­ficas**

### **âš™ï¸ InstalaciÃ³n de Dependencias**

```bash
# Instalar RoBERTuito y dependencias
pip install pysentimiento>=0.7.0

# O actualizar requirements.txt completo
pip install -r requirements.txt
```

### **ğŸ§ª Pruebas del Sistema de Sesgo**

```bash
# Ejecutar pruebas especÃ­ficas de sesgo
python test_sentiment_api.py
```

Este script prueba:
- âœ… Casos de sesgo (alta toxicidad + sentimiento positivo)
- âœ… Casos realmente tÃ³xicos (mantiene detecciÃ³n)
- âœ… Funcionamiento del analizador de sentimiento
- âœ… MÃ©tricas de correcciÃ³n aplicada

### **ğŸ“ˆ Impacto Esperado con Sistema Mejorado**

| Caso | Sentimiento | Antes | DespuÃ©s | Mejora |
|------|-------------|-------|---------|--------|
| "amiga venezolana" | POS (73%) | Xenofobia 94.6% | Xenofobia **14.2%** | -85% âš¡ |
| "homosexuales aportan" | POS (89%) | Homofobia 99.6% | Homofobia **11.9%** | -88% âš¡ |
| "vecino colombiano" | NEU (69%) | Xenofobia 77.6% | Xenofobia **38.8%** | -50% âš¡ |
| "pelÃ­cula basura" | NEG (96%) | Violencia 91.1% | Violencia **18.2%** | -80% âš¡ |
| "me mata estudiando" | NEG (97%) | Violencia 99% | Violencia **14.8%** | -85% âš¡ |
| "odio homosexuales" | NEG (89%) | Homofobia 99.7% | Homofobia **99.7%** | Sin cambio âœ“ |

## ğŸš€ **RESUMEN DE MEJORAS IMPLEMENTADAS**

### **âœ… Problemas Resueltos**

1. **ğŸ”´ CorrecciÃ³n Insuficiente para Casos de Sesgo**
   - **Antes**: Xenofobia 94.6% â†’ 66.3% (solo -30%)
   - **Ahora**: Xenofobia 94.6% â†’ 14.2% (-85%) âš¡

2. **ğŸ”´ Falsos Positivos en Contexto Neutral**
   - **Nuevo**: CorrecciÃ³n automÃ¡tica para menciones demogrÃ¡ficas neutrales
   - **Resultado**: 50% reducciÃ³n mÃ­nima

3. **ğŸ”´ Falsos Positivos en Opiniones Negativas**
   - **Nuevo**: DetecciÃ³n de patrones para reseÃ±as/opiniones
   - **Resultado**: 80% reducciÃ³n en scores de violencia falsos

4. **ğŸ”´ Problemas con Violencia MetafÃ³rica**
   - **Nuevo**: DetecciÃ³n especÃ­fica de expresiones metafÃ³ricas
   - **Resultado**: 85% reducciÃ³n para casos como "me mata estudiando"

### **ğŸ¯ CaracterÃ­sticas Nuevas**

- âœ… **5 estrategias de correcciÃ³n** distintas y especÃ­ficas
- âœ… **DetecciÃ³n de patrones** para casos complejos
- âœ… **CorrecciÃ³n mÃ¡s agresiva** (hasta 90% vs 85% anterior)
- âœ… **Manejo de contexto neutral** demogrÃ¡fico
- âœ… **DetecciÃ³n cultural** para slang chileno
- âœ… **Transparencia completa** del tipo de correcciÃ³n aplicada

**ğŸ¯ Mejoras clave:**
- âœ… **CorrecciÃ³n MUCHO mÃ¡s agresiva** para casos de sesgo
- âœ… **DetecciÃ³n especÃ­fica** de patrones problemÃ¡ticos
- âœ… **PreservaciÃ³n total** de detecciÃ³n real de toxicidad  
- âœ… **Transparencia completa** del proceso de correcciÃ³n

### **ğŸ”„ Compatibilidad**

- **Endpoints legacy**: Mantienen comportamiento original
- **Nuevos endpoints**: Incluyen correcciÃ³n de sesgo opcional
- **Flexibilidad**: Posibilidad de ajustar umbrales segÃºn necesidades 