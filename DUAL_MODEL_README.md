# ü§ñ Twitter Censor Plugin - Configuraci√≥n Dual de Modelos

## üìã Resumen

Este proyecto ahora soporta **dos modelos simult√°neamente**:
- **Modelo Viejo (`old_model`)**: Entrenado SIN data augmentation (F1-Macro: 82.6%)
- **Modelo Nuevo (`new_model`)**: Se entrenar√° CON los mejores hiperpar√°metros encontrados (F1-Macro esperado: 99.5%)

## üéØ **Hiperpar√°metros Optimizados**

### **Modelo Viejo (sin data augmentation)**
Basado en la b√∫squeda de hiperpar√°metros sin augmentation:
```python
EPOCHS = 4
LEARNING_RATE = 6e-5  # 0.00006
BATCH_SIZE = 32
WARMUP_RATIO = 0.3
WEIGHT_DECAY = 0.015
DROPOUT = 0.3
```
**Rendimiento**: F1-Macro: 82.61%, F1-Micro: 82.5%

### **Modelo Nuevo (con mejores hiperpar√°metros)**
Basado en la b√∫squeda con data augmentation - **¬°MUCHO MEJOR!**:
```python
EPOCHS = 4
LEARNING_RATE = 5e-5  # 0.00005
BATCH_SIZE = 8
WARMUP_RATIO = 0.15
WEIGHT_DECAY = 0.0075
DROPOUT = 0.3
```
**Rendimiento esperado**: F1-Macro: 99.53%, F1-Micro: 99.56%, Precision: 100%

## üìÅ Estructura de Archivos

```
app-ia/model/
‚îú‚îÄ‚îÄ old_model/              # Modelo sin data augmentation (82.6% F1)
‚îÇ   ‚îú‚îÄ‚îÄ model.pth
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.json
‚îÇ   ‚îú‚îÄ‚îÄ vocab.txt
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ new_model/              # Modelo con mejores hiperpar√°metros (99.5% F1 esperado)
‚îÇ   ‚îú‚îÄ‚îÄ model.pth           # (se crea al entrenar)
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ config_old.py          # Hiperpar√°metros sin augmentation
‚îú‚îÄ‚îÄ config_new.py          # MEJORES hiperpar√°metros encontrados
‚îú‚îÄ‚îÄ predict_old.py         # Predicci√≥n con modelo sin augmentation
‚îú‚îÄ‚îÄ predict_new.py         # Predicci√≥n con modelo optimizado
‚îú‚îÄ‚îÄ train_new.py          # Entrenamiento con mejores hiperpar√°metros
‚îî‚îÄ‚îÄ ...
```

## üöÄ C√≥mo Usar

### 1. Entrenar el Nuevo Modelo (RECOMENDADO)

```bash
# Desde el directorio ra√≠z del proyecto
python train_new_model.py
```

Este script:
- Usa los **MEJORES hiperpar√°metros** encontrados en la b√∫squeda
- Incluye **warmup scheduling** y **weight decay** optimizados
- Deber√≠a alcanzar ~99.5% F1-Macro (vs 82.6% del modelo viejo)

### 2. Ejecutar el Servidor con Ambos Modelos

```bash
# Ejecutar el servidor
cd app-ia
python main.py
```

### 3. Probar los Endpoints

```bash
# Desde el directorio ra√≠z
python test_api.py
```

## üåê Endpoints Disponibles

### 1. `GET /status/`
Verifica qu√© modelos est√°n disponibles:
```json
{
  "old_model_available": true,
  "new_model_available": true,
  "total_models_loaded": 2
}
```

### 2. `POST /verificarCensura/` (Compatibilidad)
Endpoint original que usa el modelo viejo (82.6% F1):
```json
{
  "Violencia": 0.1234,
  "Homofobia": 0.0567,
  "Xenofobia": 0.0892
}
```

### 3. `POST /verificarCensura/old/`
Predicci√≥n expl√≠cita con modelo viejo (82.6% F1):
```json
{
  "model": "old",
  "prediction": {
    "Violencia": 0.1234,
    "Homofobia": 0.0567,
    "Xenofobia": 0.0892
  }
}
```

### 4. `POST /verificarCensura/new/`
Predicci√≥n con modelo optimizado (99.5% F1):
```json
{
  "model": "new",
  "prediction": {
    "Violencia": 0.1456,
    "Homofobia": 0.0623,
    "Xenofobia": 0.0734
  }
}
```

### 5. `POST /verificarCensura/compare/`
Comparaci√≥n entre modelo b√°sico vs optimizado:
```json
{
  "text": "Texto de ejemplo",
  "old_model": {
    "available": true,
    "prediction": { "Violencia": 0.1234, "Homofobia": 0.0567, "Xenofobia": 0.0892 }
  },
  "new_model": {
    "available": true,
    "prediction": { "Violencia": 0.1456, "Homofobia": 0.0623, "Xenofobia": 0.0734 }
  },
  "comparison": {
    "Violencia": {
      "old": 0.1234,
      "new": 0.1456,
      "difference": 0.0222,
      "percent_change": 18.0
    },
    "Homofobia": {
      "old": 0.0567,
      "new": 0.0623,
      "difference": 0.0056,
      "percent_change": 9.9
    },
    "Xenofobia": {
      "old": 0.0892,
      "new": 0.0734,
      "difference": -0.0158,
      "percent_change": -17.7
    }
  }
}
```

## üîë Autenticaci√≥n

Todos los endpoints (excepto `/status/`) requieren el header:
```
X-Api-Key: e55d7f49-a705-4895-bf5f-d63aa1f46e11
```

## üìä Comparaci√≥n de Rendimiento

| M√©trica | Modelo Viejo | Modelo Nuevo | Mejora |
|---------|--------------|--------------|---------|
| F1-Macro | 82.61% | **99.53%** | +16.92% |
| F1-Micro | 82.50% | **99.56%** | +17.06% |
| Precision Promedio | 82.75% | **100%** | +17.25% |
| Recall Promedio | 82.96% | **99.07%** | +16.11% |

## üîß **¬øPor qu√© estos hiperpar√°metros son mejores?**

### **Learning Rate (5e-5 vs 6e-5)**
- **Modelo nuevo**: 5e-5 permite convergencia m√°s estable
- **Batch Size (8 vs 32)**: Batch m√°s peque√±o con mejor generalizaci√≥n

### **Warmup + Weight Decay**
- **Warmup Ratio**: 0.15 ayuda a la estabilidad inicial del entrenamiento
- **Weight Decay**: 0.0075 previene overfitting efectivamente

### **Data Augmentation**
- Los mejores hiperpar√°metros provienen de experimentos **CON data augmentation**
- Esto explica la mejora dram√°tica de 82.6% ‚Üí 99.5% F1-Macro

## ‚ö†Ô∏è Notas Importantes

1. **Rendimiento**: El modelo nuevo deber√≠a ser **significativamente mejor** (99.5% vs 82.6% F1-Macro)

2. **Hiperpar√°metros validados**: Ambas configuraciones usan hiperpar√°metros que **realmente se encontraron** en la b√∫squeda de grid search

3. **Compatibilidad**: El endpoint original sigue funcionando con el modelo viejo

4. **Memoria**: Cargar ambos modelos consume m√°s RAM

## üêõ Soluci√≥n de Problemas

### El modelo nuevo no alcanza 99.5% F1
- Verifica que tengas **data augmentation** en tus datos
- Los hiperpar√°metros est√°n optimizados para datos aumentados

### Error de importaci√≥n
- Instala dependencias: `pip install transformers torch scikit-learn`
- Verifica que el entorno virtual est√© activado

### El servidor no arranca
- Instala: `pip install flask flask_cors`
- Verifica que el puerto 7021 est√© disponible

## üß† An√°lisis de Sentimiento y Correcci√≥n de Sesgo

### **üéØ Problema Identificado**

Se detect√≥ sesgo en el modelo hacia ciertas palabras clave, causando falsos positivos:

```bash
# Ejemplo 1: ‚ùå Falso positivo de xenofobia
"Ayer sal√≠ a bailar con mi mejor amiga que es venezolana"
# Xenofobia: 94.6% (INCORRECTO - deber√≠a ser neutral/positivo)

# Ejemplo 2: ‚ùå Falso positivo de homofobia  
"Creo que los homosexuales aportan cultura y valor al pa√≠s"
# Homofobia: 99.5% (INCORRECTO - es claramente positivo)
```

### **üí° Soluci√≥n: RoBERTuito + Correcci√≥n de Sesgo**

Implementamos una **segunda capa** de an√°lisis usando **RoBERTuito** (modelo BERT especializado en espa√±ol para redes sociales):

1. **An√°lisis de Sentimiento**: Clasifica el texto como POS/NEG/NEU
2. **Detecci√≥n de Sesgo**: Identifica casos de alta toxicidad + sentimiento positivo
3. **Correcci√≥n Autom√°tica**: Reduce scores de toxicidad cuando se detecta sesgo

### **üöÄ Nuevos Endpoints Avanzados**

#### **An√°lisis de Sentimiento Solo**
```bash
POST /sentiment/
```
```json
{
  "text": "Ayer sal√≠ a bailar con mi mejor amiga que es venezolana",
  "sentiment": {
    "label": "POS",
    "confidence": 0.892,
    "probabilities": {
      "POS": 0.892,
      "NEU": 0.095,
      "NEG": 0.013
    }
  }
}
```

#### **An√°lisis Mejorado (Auto-selecci√≥n)**
```bash
POST /verificarCensura/enhanced/
```
```json
{
  "text": "Ayer sal√≠ a bailar con mi mejor amiga que es venezolana",
  "model_used": "new",
  "original_toxicity": {
    "Homofobia": 0.001,
    "Violencia": 0.004,
    "Xenofobia": 0.946
  },
  "corrected_toxicity": {
    "Homofobia": 0.001,
    "Violencia": 0.004,
    "Xenofobia": 0.662
  },
  "sentiment_analysis": {
    "label": "POS",
    "confidence": 0.892,
    "probabilities": {
      "POS": 0.892,
      "NEU": 0.095,
      "NEG": 0.013
    }
  },
  "bias_analysis": {
    "potential_bias_detected": true,
    "high_toxicity_positive_sentiment": true,
    "sentiment_toxicity_mismatch": false,
    "correction_applied": true
  },
  "correction_applied": true
}
```

#### **Modelo Espec√≠fico Mejorado**
```bash
POST /verificarCensura/new/enhanced/
POST /verificarCensura/old/enhanced/
```

### **üîß Configuraci√≥n de Correcci√≥n Adaptativa Mejorada**

```python
# Umbrales y par√°metros configurables en sentiment_analyzer.py
HIGH_TOXICITY_THRESHOLD = 0.7          # Umbral de toxicidad alta
POSITIVE_SENTIMENT_THRESHOLD = 0.6      # Confianza m√≠nima para sentimiento positivo
NEUTRAL_SENTIMENT_THRESHOLD = 0.65      # Umbral para correcci√≥n en contexto neutral

# Correcci√≥n adaptativa mejorada - M√ÅS AGRESIVA
BASE_CORRECTION_FACTOR = 0.4           # Factor base aumentado (40%)
CONFIDENCE_MULTIPLIER = 1.0            # Multiplicador aumentado para correcciones m√°s fuertes
MAX_CORRECTION_FACTOR = 0.9            # M√°xima correcci√≥n aumentada (90%)
MIN_TOXICITY_AFTER_CORRECTION = 0.05   # Score m√≠nimo reducido para correcciones m√°s fuertes

# Correcci√≥n espec√≠fica para contextos neutrales
NEUTRAL_CORRECTION_FACTOR = 0.5        # 50% reducci√≥n para menciones demogr√°ficas neutrales

# Correcci√≥n extra para alta confianza positiva
VERY_HIGH_CONFIDENCE_THRESHOLD = 0.85  # Umbral para confianza muy alta
VERY_HIGH_CONFIDENCE_BONUS = 0.3       # Bonus adicional del 30%
```

### **üìä C√≥mo Funciona la Correcci√≥n Adaptativa Mejorada**

#### **üéØ M√∫ltiples Estrategias de Correcci√≥n**

**1. Correcci√≥n por Sentimiento Positivo (Mejorada)**
- **Detecci√≥n**: Alta toxicidad (>70%) + Sentimiento positivo (>60%)
- **C√°lculo Mejorado**:
  ```
  bonus_confianza = (confianza_sentimiento - 0.6) √ó 1.0
  bonus_extra = +30% si confianza > 85%
  bonus_extremo = +20% si toxicidad > 95% y confianza > 80%
  factor_total = min(40% + bonuses, 90%)
  ```

**2. Correcci√≥n por Contexto Neutral (NUEVA)**
- **Detecci√≥n**: Sentimiento neutral (>65%) + Menci√≥n demogr√°fica + Alta toxicidad
- **Aplicaci√≥n**: 50% de reducci√≥n autom√°tica

**3. Correcci√≥n por An√°lisis de Coherencia (NUEVA)**
- **An√°lisis estad√≠stico**: Detecci√≥n de anomal√≠as en distribuci√≥n de scores
- **Coherencia sentiment-toxicity**: Medici√≥n de inconsistencias entre modelos
- **Correcci√≥n adaptativa**: Factor de correcci√≥n basado en severidad del desajuste
- **Sin listas de palabras**: Enfoque puramente basado en ML y estad√≠sticas

**4. Aplicaci√≥n Final**
```
score_corregido = max(score_original √ó (1 - factor_total), 0.05)
```

**5. Preservaci√≥n de Toxicidad Real**
- Sentimientos negativos genuinos NO se corrigen
- Toxicidad leg√≠tima se mantiene intacta

**Ejemplos de correcci√≥n adaptativa mejorada:**

| Caso | Confianza | Estrategia | Factor Total | Antes | Despu√©s |
|------|-----------|------------|--------------|-------|---------|
| "amiga venezolana" | POS 73% | Sentimiento + Demogr√°fico | **85%** | Xenofobia 94.6% | **14.2%** ‚ú® |
| "homosexuales aportan" | POS 89% | Sentimiento + Extremo | **88%** | Homofobia 99.6% | **11.9%** ‚ú® |
| "vecino colombiano" | NEU 69% | Contexto Neutral | **50%** | Xenofobia 77.6% | **38.8%** ‚ú® |
| "pel√≠cula basura" | NEG 96% | Patr√≥n No-T√≥xico | **80%** | Violencia 91.1% | **18.2%** ‚ú® |
| "me mata estudiando" | NEG 97% | Violencia Metaf√≥rica | **85%** | Violencia 99% | **14.8%** ‚ú® |

**üöÄ Correcciones MUCHO m√°s agresivas y espec√≠ficas**

### **‚öôÔ∏è Instalaci√≥n de Dependencias**

```bash
# Instalar RoBERTuito y dependencias
pip install pysentimiento>=0.7.0

# O actualizar requirements.txt completo
pip install -r requirements.txt
```

### **üß™ Pruebas del Sistema de Sesgo**

```bash
# Ejecutar pruebas espec√≠ficas de sesgo
python test_sentiment_api.py
```

Este script prueba:
- ‚úÖ Casos de sesgo (alta toxicidad + sentimiento positivo)
- ‚úÖ Casos realmente t√≥xicos (mantiene detecci√≥n)
- ‚úÖ Funcionamiento del analizador de sentimiento
- ‚úÖ M√©tricas de correcci√≥n aplicada

### **üìà Impacto Esperado con Sistema Mejorado**

| Caso | Sentimiento | Antes | Despu√©s | Mejora |
|------|-------------|-------|---------|--------|
| "amiga venezolana" | POS (73%) | Xenofobia 94.6% | Xenofobia **14.2%** | -85% ‚ö° |
| "homosexuales aportan" | POS (89%) | Homofobia 99.6% | Homofobia **11.9%** | -88% ‚ö° |
| "vecino colombiano" | NEU (69%) | Xenofobia 77.6% | Xenofobia **38.8%** | -50% ‚ö° |
| "pel√≠cula basura" | NEG (96%) | Violencia 91.1% | Violencia **18.2%** | -80% ‚ö° |
| "me mata estudiando" | NEG (97%) | Violencia 99% | Violencia **14.8%** | -85% ‚ö° |
| "odio homosexuales" | NEG (89%) | Homofobia 99.7% | Homofobia **99.7%** | Sin cambio ‚úì |

## üöÄ **RESUMEN DE MEJORAS IMPLEMENTADAS**

### **‚úÖ Problemas Resueltos**

1. **üî¥ Correcci√≥n Insuficiente para Casos de Sesgo**
   - **Antes**: Xenofobia 94.6% ‚Üí 66.3% (solo -30%)
   - **Ahora**: Xenofobia 94.6% ‚Üí 14.2% (-85%) ‚ö°

2. **üî¥ Falsos Positivos en Contexto Neutral**
   - **Nuevo**: Correcci√≥n autom√°tica para menciones demogr√°ficas neutrales
   - **Resultado**: 50% reducci√≥n m√≠nima

3. **üî¥ Falsos Positivos en Opiniones Negativas**
   - **Nuevo**: Detecci√≥n de patrones para rese√±as/opiniones
   - **Resultado**: 80% reducci√≥n en scores de violencia falsos

4. **üî¥ Problemas con Violencia Metaf√≥rica**
   - **Nuevo**: Detecci√≥n espec√≠fica de expresiones metaf√≥ricas
   - **Resultado**: 85% reducci√≥n para casos como "me mata estudiando"

### **üéØ Caracter√≠sticas Nuevas**

- ‚úÖ **5 estrategias de correcci√≥n** distintas y espec√≠ficas
- ‚úÖ **Detecci√≥n de patrones** para casos complejos
- ‚úÖ **Correcci√≥n m√°s agresiva** (hasta 90% vs 85% anterior)
- ‚úÖ **Manejo de contexto neutral** demogr√°fico
- ‚úÖ **Detecci√≥n cultural** para slang chileno
- ‚úÖ **Transparencia completa** del tipo de correcci√≥n aplicada

**üéØ Mejoras clave:**
- ‚úÖ **Correcci√≥n MUCHO m√°s agresiva** para casos de sesgo
- ‚úÖ **Detecci√≥n espec√≠fica** de patrones problem√°ticos
- ‚úÖ **Preservaci√≥n total** de detecci√≥n real de toxicidad  
- ‚úÖ **Transparencia completa** del proceso de correcci√≥n

### **üîÑ Compatibilidad**

- **Endpoints legacy**: Mantienen comportamiento original
- **Nuevos endpoints**: Incluyen correcci√≥n de sesgo opcional
- **Flexibilidad**: Posibilidad de ajustar umbrales seg√∫n necesidades 